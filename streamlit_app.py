import streamlit as st
import torch
from nltk.tokenize import word_tokenize
from torch.nn import functional as F
import json
from fasttext_cnn import CNN_NLP
import gdown
from py3langid.langid import LanguageIdentifier, MODEL_FILE

cache = {
    "models": {},
    "word2idx": {}
}

drive_dict = {"ca": "1l4XB4PYsaMTX6w0uWcu4hX1EV9ovfB2U",
              "en": "1EvsBkfiA0mZTA75XPFlMu9GifMvrR8Nq",
              "es": "1dUW-9DknLwZhNH57X6A4166qRlzNFHz8",
              "eu" : "1Sdvay2OV2zsZ3m0GudwC5nLkivekTcsc", 
              "gl" : "1p41UWR43Je-Bgxw-QP-J_5ZzafZS5NHZ",
              "pt": "1r411nMfeL0Njpjhj2LL6RtWAv0903XA3"}

# Cargar modelos y word2idx desde archivos (reemplaza las rutas con las correctas)
def load_model_and_word2idx(language):
    if language in cache["models"] and language in cache["word2idx"]:
        return cache["models"][language], cache["word2idx"][language]
    
    url = f'https://drive.google.com/uc?id={drive_dict[language]}'
    output = f'modelo_{language}.pkl'
    gdown.download(url, output, quiet=False)

    model = torch.load(f'modelo_{language}.pkl', map_location=torch.device('cpu'))
    word2idx_path = f'word2idx/word2idx_{language}.json'

    with open(word2idx_path, 'r') as f:
        word2idx = json.load(f)

    cache["models"][language] = model
    cache["word2idx"][language] = word2idx

    return model, word2idx

# Prediction function
def predict(text, model, word2idx):
    """Predict probability that a review is AI generated."""
    max_len = 62

    # Tokenize, pad and encode text
    tokens = word_tokenize(text.lower())
    padded_tokens = tokens + ['<pad>'] * (max_len - len(tokens))
    input_id = [word2idx.get(token, word2idx['<unk>']) for token in padded_tokens]

    # Convert to PyTorch tensors
    input_id = torch.tensor(input_id).unsqueeze(dim=0)

    # Compute logits
    logits = model.forward(input_id)

    # Compute probability
    probs = F.softmax(logits, dim=1).squeeze(dim=0)

    return probs[1] * 100

# Language detection function
def detect_language(text):
    identifier = LanguageIdentifier.from_pickled_model(MODEL_FILE)
    identifier.set_languages(['en', 'es', 'pt', 'gl', 'eu', 'ca'])

    return identifier.classify(text)[0]

def display_home():
    st.title("Detect AI Content")

    text = st.text_area("Enter your text:", height=200)

    if st.button("Detect AI Content"):
        if text and len(text) > 250:
            detected_language = detect_language(text)
            model, word2idx = load_model_and_word2idx(detected_language)
            
            paragraphs = text.split('\n\n')
            total_paragraphs = 0
            
            st.markdown("<div style='text-align: center;'>AI-generated paragraphs are highlighted in <span style='color: red; font-weight: bold;'>red</span>, human-generated paragraphs are in <span style='color: green; font-weight: bold;'>green</span>.</div>", unsafe_allow_html=True)
            
            for paragraph in paragraphs:
                if paragraph.strip() != "":
                    total_paragraphs += 1
                    ai_probability = predict(paragraph, model, word2idx)
                    if ai_probability > 99:
                        st.markdown(f"<div style='background-color: rgba(255, 0, 0, 0.05); color: red; padding: 8px; border-radius: 5px;'>{paragraph}</div>", unsafe_allow_html=True)
                    else:
                        st.markdown(f"<div style='background-color: rgba(0, 255, 0, 0.05); color: green; padding: 8px; border-radius: 5px;'>{paragraph}</div>", unsafe_allow_html=True)
            
        else:
            error_message = "Please enter text with more than 250 characters before detecting AI content." if not text else "Text must be longer than 250 characters."
            st.error(error_message)

def display_problem():
    st.title("About the Problem")
    st.write("Detection of automatically generated text is a crucial challenge in the field of Artificial Intelligence and Natural Language Processing (NLP). With the advent of large-scale language models (LLMs), such as GPT-3.5, GPT-4, LLaMA, Mistral, Cohere, among others, automated text generation has become more accessible and sophisticated than ever before.")

    st.write("The sophistication of the models has made it increasingly difficult to distinguish AI-generated text from human-generated text. Precisely, in the framework of IberAuTexTification, we face the challenge of identifying texts that have been automatically generated by these powerful language models. This includes texts in a variety of languages such as Spanish, Catalan, Basque, Galician, Portuguese, and English (in Gibraltar), as well as in different domains such as news, reviews, emails, essays, dialogues, Wikipedia, among others.")

    st.image("assets/es.png", width=100)
    st.image("assets/ca.png", width=100)
    st.image("assets/eu.png", width=100)
    st.image("assets/gl.png", width=100)
    st.image("assets/pt.png", width=100)
    st.image("assets/en.png", width=100)


def display_aboutus():
    st.markdown(
    """
    <style>
    .reportview-container {
        max-width: 100%;
    }
    main {
        padding: 0;
    }
    </style>
    """,
    unsafe_allow_html=True,
    )

    st.title("About Us")

    # Información sobre el proyecto y el equipo
    st.write(
        "We are third-year data science students at the Polytechnic University of Valencia (UPV). "
        "This project, part of our Project 3 course, allows us to apply our data science knowledge "
        "and reflect on AI's societal impact, including ethical, social, and cultural issues. "
        "Collaborating on this project enhances our technical skills and encourages creativity, "
        "analytical thinking, and teamwork, helping us understand the complexities of language and "
        "the interplay between human creativity and machine mimicry."
    )

    st.title("Our Team")

    # Información sobre cada miembro del equipo
    team_members = [
        {"name": "Eurídice Corbí", "linkedin": "https://www.linkedin.com/in/eur%C3%ADdice-corb%C3%AD/", "image": "assets/euri.jpg"},
        {"name": "Natalia Hernández", "linkedin": "https://www.linkedin.com/in/natalia-hern%C3%A1ndez-23b5882b7/", "image": "assets/natalia.jpg"},
        {"name": "Nicolás Nebot", "linkedin": "https://www.linkedin.com/in/niko-nebot-silvestre-a29107293", "image": "assets/nicolás.png"},
        {"name": "Wojciech Neuman", "linkedin": "https://www.linkedin.com/in/wojciechneuman/", "image": "assets/wojciech.jpg"},
        {"name": "Aitana Sebastiá", "linkedin": "https://www.linkedin.com/in/aitana-sebasti%C3%A0-espinosa-26a8bb2a0/", "image": "assets/aitana.jpg"},
        {"name": "Carlos Torregrosa", "linkedin": "https://www.linkedin.com/in/carlos-torregrosa-alcayde-a3274330a/", "image": "assets/carlos.png"},
        {"name": "Jose Valero", "linkedin": "https://www.linkedin.com/in/jose-valero-sanchis", "image": "assets/jose.jpg"},
    ]

    col1, col2, col3 = st.columns(3)

    for i, member in enumerate(team_members):
        if i < 3:
            with col1:
                st.image(member["image"], width=100)
            with col2:
                st.subheader(member["name"])
            with col3:
                st.write(f"[LinkedIn ({member['name']})]({member['linkedin']})")
        elif i < 6:
            with col1:
                st.image(member["image"], width=100)
            with col2:
                st.subheader(member["name"])
            with col3:
                st.write(f"[LinkedIn ({member['name']})]({member['linkedin']})")
        else:
            col2.image(member["image"], width=100)
            col2.subheader(member["name"])
            col2.write(f"[LinkedIn ({member['name']})]({member['linkedin']})")

def display_approach():
    st.title("Our Approach")
    st.write("To address the problem, we have tried a large number of models as well as ways to represent the texts. Finally, the combination that gave us the best results was the following:")
    st.subheader("Text Representation")
    st.write("...")
    # Aquí puedes detallar tu enfoque para la representación de texto.
    # Puedes usar st.write() para explicar y st.image() para mostrar imágenes relacionadas.
    st.subheader("Model")
    st.write("...")
    # Aquí puedes explicar tu elección de modelo.

def main():
    # st.sidebar.title("Navigation")
    # page = st.sidebar.selectbox("Go to", ["Home", "About the Problem", "About Us", "Our Approach"])

    # if page == "Home":
    display_home()
    # elif page == "About the Problem":
    #     display_problem()
    # elif page == "About Us":
    #     display_aboutus()
    # elif page == "Our Approach":
    #     display_approach()

if __name__ == "__main__":
    main()